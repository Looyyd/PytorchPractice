{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:38:36.126893Z",
     "start_time": "2024-01-15T21:38:36.098384Z"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import optuna\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map\n",
    "from gymnasium.vector import AsyncVectorEnv, SyncVectorEnv\n",
    "from collections import deque\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "FrozenLake environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f83b02f493c38fc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "env = gym.make('FrozenLake-v1', is_slippery=False)\n",
    "n_actions = env.action_space.n\n",
    "n_states = env.observation_space.n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:38:36.138059Z",
     "start_time": "2024-01-15T21:38:36.129834Z"
    }
   },
   "id": "f6f1fa210c2ad0e",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def convert_layout_to_tensor(map_layouts):\n",
    "    nrows, ncols = len(map_layouts[0]), len(map_layouts[0][0])\n",
    "    num_statuses = 4\n",
    "    batch_size = len(map_layouts)\n",
    "\n",
    "    # Initialize a tensor for the batch of layouts\n",
    "    layout_tensor = torch.zeros((batch_size, nrows, ncols, num_statuses), device='cpu', dtype=torch.float)\n",
    "\n",
    "    layout_to_val = {b'F': 0, b'H': 1, b'S': 0, b'G': 3,\n",
    "                     'F': 0, 'H': 1, 'S': 0, 'G': 3}\n",
    "\n",
    "    # Precompute all indices for the batch\n",
    "    all_indices = [\n",
    "        layout_to_val[item]\n",
    "        for map_layout in map_layouts\n",
    "        for row in map_layout\n",
    "        for item in row\n",
    "    ]\n",
    "    indices_tensor = torch.tensor(all_indices, device='cpu').view(batch_size, nrows, ncols)\n",
    "\n",
    "    # Update the tensor using advanced indexing\n",
    "    layout_tensor.scatter_(3, indices_tensor.unsqueeze(3), 1)\n",
    "\n",
    "    return layout_tensor\n",
    "\n",
    "\n",
    "def update_start_positions(tensor_layout:Tensor, positions):\n",
    "    nrows, ncols, _ = tensor_layout.size()[1:4]\n",
    "\n",
    "    # Convert positions to a PyTorch tensor if it's not already one\n",
    "    if not isinstance(positions, torch.Tensor):\n",
    "        positions = torch.tensor(positions, dtype=torch.long, device=tensor_layout.device)\n",
    "\n",
    "    # Calculate rows and columns for all positions\n",
    "    rows = positions // ncols\n",
    "    cols = positions % ncols\n",
    "\n",
    "    # Reset the cells to [0, 0, 0, 0]\n",
    "    tensor_layout[torch.arange(positions.size(0)), rows, cols] = torch.tensor([0, 0, 0, 0], dtype=tensor_layout.dtype, device=tensor_layout.device)\n",
    "\n",
    "    # Set the start cells to [0, 0, 1, 0]\n",
    "    tensor_layout[torch.arange(positions.size(0)), rows, cols, 2] = 1\n",
    "\n",
    "    return tensor_layout"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:38:36.138401Z",
     "start_time": "2024-01-15T21:38:36.134377Z"
    }
   },
   "id": "44567364fcc9fa67",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 1.]]]])\n",
      "tensor([[[[0., 0., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "tensor = convert_layout_to_tensor(generate_random_map(4))\n",
    "print(tensor)\n",
    "updated_tensor = update_start_positions(tensor, [[0]])\n",
    "print(updated_tensor) # dimensions: batch_size x nrows x ncols x num_statuses\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:38:36.142043Z",
     "start_time": "2024-01-15T21:38:36.137862Z"
    }
   },
   "id": "26914cb622923df9",
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implementation of DeamerV3 model\n",
    "![DeamerV3 model](model_names.png)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dd95da8c410c3ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Autoencoder that learns the latent space of the data\n",
    "class CategoricalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, latent_dim, num_categories):\n",
    "        super(CategoricalAutoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_categories = num_categories\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, latent_dim * num_categories)  # Output logits for each category in each latent dimension\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim * num_categories, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, input_size),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, temperature=1.0):\n",
    "        # Encode input and apply Gumbel Softmax\n",
    "        encoded = self.encoder(x)\n",
    "        encoded = encoded.view(-1, self.num_categories)\n",
    "        softmax = nn.functional.gumbel_softmax(encoded, tau=temperature, hard=True)\n",
    "        return softmax\n",
    "\n",
    "    def forward(self, x, temperature=1.0):\n",
    "        batch_size = x.size(0)\n",
    "        softmax = self.encode(x, temperature)\n",
    "        softmax = softmax.view(batch_size, -1)\n",
    "\n",
    "        x = self.decoder(softmax)\n",
    "        return x, softmax\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:38:36.150027Z",
     "start_time": "2024-01-15T21:38:36.143316Z"
    }
   },
   "id": "19b3561be99fe27f",
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sequence model that learns the dynamics of the latent space\n",
    "# takes as input h t-1, z t-1, a t-1 and outputs ht\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:38:36.162923Z",
     "start_time": "2024-01-15T21:38:36.146198Z"
    }
   },
   "id": "d35de25f9599dd11",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class WorldModel(nn.Module):\n",
    "    def __init__(self, input_size, xt_size, gru_hidden_size, num_layers, zt_dim, num_categories, reward_size, continue_size):\n",
    "        super(WorldModel, self).__init__()\n",
    "\n",
    "        self.gru_hidden_size = gru_hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_categories = num_categories\n",
    "        \n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, gru_hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "\n",
    "        # Specific predictor for the latent space zt\n",
    "        self.dynamics_predictor = nn.Sequential(\n",
    "            nn.Linear(gru_hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, zt_dim * num_categories)\n",
    "        )\n",
    "        \n",
    "        # Specific predictor for the reward rt\n",
    "        self.reward_predictor = nn.Sequential(\n",
    "            nn.Linear(gru_hidden_size+ zt_dim * num_categories, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, reward_size)\n",
    "        )\n",
    "        \n",
    "        # Specific predictor for the continue signal ct\n",
    "        self.continue_predictor = nn.Sequential(\n",
    "            nn.Linear(gru_hidden_size + zt_dim * num_categories, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, continue_size)\n",
    "        )\n",
    "        \n",
    "        self.decoder_predictor = nn.Sequential(\n",
    "            nn.Linear(gru_hidden_size + zt_dim * num_categories, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, xt_size)\n",
    "        )\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(gru_hidden_size + xt_size, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, zt_dim * num_categories)  # Output logits for each category in each latent dimension\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, ztat, xt, ht_1):\n",
    "        if ht_1 is None:\n",
    "            # Initialize hidden state with zeros if not provided\n",
    "            h0 = torch.zeros(self.num_layers, ztat.size(0), self.gru_hidden_size).to(xt.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        _ , ht = self.gru(ztat, ht_1)\n",
    "       \n",
    "        zt = self.encode(xt, ht)\n",
    "        \n",
    "        zt_hat = self.dynamics_predictor(ht)\n",
    "\n",
    "        htzt = torch.cat((ht.view(1, -1), zt.view(1, -1)), dim=1)\n",
    "        rt_hat = self.reward_predictor(htzt)\n",
    "        ct_hat = self.continue_predictor(htzt)\n",
    "        xt_hat = self.decoder_predictor(htzt)\n",
    "    \n",
    "        return ht, zt_hat, rt_hat, ct_hat, xt_hat, zt\n",
    "    \n",
    "    def encode(self, xt, ht, temperature=1.0):\n",
    "        # Encode input and apply Gumbel Softmax\n",
    "        # ht has is 1,1,32 need to be 1,32\n",
    "\n",
    "        ht = ht.view(-1, self.gru_hidden_size)\n",
    "        encoded = self.encoder(torch.cat((xt, ht), dim=1))\n",
    "        encoded = encoded.view(-1, self.num_categories)\n",
    "        softmax = nn.functional.gumbel_softmax(encoded, tau=temperature, hard=True)\n",
    "        return softmax\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:38:36.164825Z",
     "start_time": "2024-01-15T21:38:36.151976Z"
    }
   },
   "id": "cc7ed508cc0c5986",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def symlog(x):\n",
    "    \"\"\"Symmetric log transformation\"\"\"\n",
    "    return torch.sign(x) * torch.log(torch.abs(x) + 1)\n",
    "\n",
    "def symexp(x):\n",
    "    \"\"\"Inverse of symmetric log transformation\"\"\"\n",
    "    return torch.sign(x) * (torch.exp(torch.abs(x)) - 1)\n",
    "\n",
    "class SymlogLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SymlogLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # Apply symlog transformation to the target\n",
    "        transformed_target = symlog(target)\n",
    "        # Compute MSE Loss between input and transformed target\n",
    "        return F.mse_loss(input, transformed_target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:38:36.165087Z",
     "start_time": "2024-01-15T21:38:36.154957Z"
    }
   },
   "id": "c75090797e8abeae",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the Actor Network\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 128)\n",
    "        self.fc2 = nn.Linear(128, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        action_probs = torch.softmax(self.fc2(x), dim=-1)\n",
    "        return action_probs\n",
    "\n",
    "# Define the Critic Network\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_size):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        value = self.fc2(x)\n",
    "        return value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:38:36.165325Z",
     "start_time": "2024-01-15T21:38:36.158110Z"
    }
   },
   "id": "7f334ff705d60e11",
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "640b615c97d3cb37"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = \"mps\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:38:36.165541Z",
     "start_time": "2024-01-15T21:38:36.160499Z"
    }
   },
   "id": "21168a3b14a069b2",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "latent_size = 32 # aka zt size\n",
    "num_categories = 4 # number of categories in latent space\n",
    "#autoencoder = CategoricalAutoencoder(4*4*4, latent_size, num_categories).to(device)\n",
    "#autoencoder_optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "ht_size = 32\n",
    "xt_size = 4*4*4\n",
    "reward_size = 1\n",
    "continue_size = 1\n",
    "worldModel = WorldModel(latent_size * num_categories + n_actions, xt_size, ht_size, 1, latent_size, num_categories, reward_size, continue_size).to(device)\n",
    "worldModel_optimizer = optim.Adam(worldModel.parameters(), lr=1e-4, eps=1e-8)\n",
    "\n",
    "actor = Actor(ht_size, n_actions).to(device)\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=3e-5, eps=1e-5)\n",
    "critic = Critic(ht_size).to(device)\n",
    "critic_optimizer = optim.Adam(critic.parameters(), lr=3e-5, eps=1e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:38:36.186193Z",
     "start_time": "2024-01-15T21:38:36.167526Z"
    }
   },
   "id": "6186b465c849ee41",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mloyd\u001B[0m (\u001B[33mloyd-team\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.1"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/loyd/PycharmProjects/PytorchPractice/notebooks/dreamer/wandb/run-20240115_223837-2zyhqijp</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/loyd-team/Dreamerv3%20Reproduction/runs/2zyhqijp' target=\"_blank\">Refactor to follow paper model definitions and losses</a></strong> to <a href='https://wandb.ai/loyd-team/Dreamerv3%20Reproduction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/loyd-team/Dreamerv3%20Reproduction' target=\"_blank\">https://wandb.ai/loyd-team/Dreamerv3%20Reproduction</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/loyd-team/Dreamerv3%20Reproduction/runs/2zyhqijp' target=\"_blank\">https://wandb.ai/loyd-team/Dreamerv3%20Reproduction/runs/2zyhqijp</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:26<00:00,  2.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded (0.003 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6eedab745cd147f2a3e8813aeddc23d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "W&B sync reduced upload amount by 13.8%             "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_grads</td><td>▅▆▁▂▁▁▁▄▂▁▄▁█▁▁▁█▁▂▁▁▁▁▁▂▁▂▂▁▂▁▂▂▁▂▁▂▂▂▄</td></tr><tr><td>actor_loss</td><td>█▆▄▃▄▄▄▆▄▄▃▄▁▄▄▄▁▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄▂</td></tr><tr><td>actor_weights_norm</td><td>▁▁▁▁▁▁▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇███████▇▇▇▇█</td></tr><tr><td>critic_grads</td><td>▆▇▂▃▁▁▁▅▂▁▄▁█▁▁▁█▁▂▁▁▁▁▁▂▁▃▂▁▂▁▂▂▁▂▁▂▂▃▄</td></tr><tr><td>critic_loss</td><td>█▃▁▁▁▁▁▂▁▁▁▁▃▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>critic_weights_norm</td><td>█▅▅▄▄▅▅█▅▃▂▃▃▃▄▄▆▅▅▆█▇▆▇▇▆▄▃▂▁▁▁▂▃▄▄▅▄▄▂</td></tr><tr><td>dynamic_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>integratedModel_grads</td><td>▄▂▂▂▂▂▃▂▂▁▆▁▆▂▃▂▆▁▂▂▂▂▁▂▂▁▂▃▁▂▁▁▃▂▂▂▂▄▃█</td></tr><tr><td>integratedModel_loss</td><td>▃▁▁▁▂▁▁▁▁▁▆▁▇▁▂▁▇▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▂▂█</td></tr><tr><td>integratedModel_weights_norm</td><td>▁▂▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>prediction_loss</td><td>▃▁▁▁▂▁▁▁▁▁▆▁▇▁▂▁▇▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▂▂█</td></tr><tr><td>previous_episode_reward</td><td>▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>representation_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_grads</td><td>0.10182</td></tr><tr><td>actor_loss</td><td>-0.02751</td></tr><tr><td>actor_weights_norm</td><td>8.9747</td></tr><tr><td>critic_grads</td><td>0.2376</td></tr><tr><td>critic_loss</td><td>0.0007</td></tr><tr><td>critic_weights_norm</td><td>8.22953</td></tr><tr><td>dynamic_loss</td><td>1.0</td></tr><tr><td>integratedModel_grads</td><td>4.76227</td></tr><tr><td>integratedModel_loss</td><td>0.67935</td></tr><tr><td>integratedModel_weights_norm</td><td>97.26311</td></tr><tr><td>prediction_loss</td><td>0.07935</td></tr><tr><td>previous_episode_reward</td><td>0.0</td></tr><tr><td>representation_loss</td><td>1.0</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">Refactor to follow paper model definitions and losses</strong> at: <a href='https://wandb.ai/loyd-team/Dreamerv3%20Reproduction/runs/2zyhqijp' target=\"_blank\">https://wandb.ai/loyd-team/Dreamerv3%20Reproduction/runs/2zyhqijp</a><br/> View job at <a href='https://wandb.ai/loyd-team/Dreamerv3%20Reproduction/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMDQ0MzAzMQ==/version_details/v6' target=\"_blank\">https://wandb.ai/loyd-team/Dreamerv3%20Reproduction/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMDQ0MzAzMQ==/version_details/v6</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20240115_223837-2zyhqijp/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "num_episodes = 1000\n",
    "gamma = 0.997\n",
    "Bpred = 1\n",
    "Bdyn = 0.5\n",
    "Brep = 0.1\n",
    "loss_fn = SymlogLoss()\n",
    "kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "logging = True\n",
    "\n",
    "if logging:\n",
    "    wandb.init(project=\"Dreamerv3 Reproduction\",\n",
    "               name=\"Refactor to follow paper model definitions and losses\",\n",
    "               reinit=True,\n",
    "               config={\"num_episodes\": num_episodes,\n",
    "                       \"gamma\": gamma,\n",
    "                       \"latent_size\": latent_size,\n",
    "                       \"num_categories\": num_categories,\n",
    "                       \"ht_size\": ht_size,\n",
    "                       \"reward_size\": reward_size,\n",
    "                       \"continue_size\": continue_size,\n",
    "                       \"worldModel_optimizer\": worldModel_optimizer,\n",
    "                       \"actor_optimizer\": actor_optimizer,\n",
    "                       \"critic_optimizer\": critic_optimizer})\n",
    "\n",
    "\n",
    "previous_episode_reward = 0\n",
    "for episode in tqdm(range(num_episodes)):\n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "    episode_rewards = []\n",
    "    layout_tensor = convert_layout_to_tensor([env.desc]).to(device)\n",
    "    hidden_state = torch.zeros((1, 1, ht_size), device=device, dtype=torch.float)\n",
    "    max_steps = 100\n",
    "\n",
    "    while not done and max_steps > 0:\n",
    "        state_tensor = update_start_positions(layout_tensor, [state])\n",
    "        state_tensor = state_tensor.view(1, -1).to(device)\n",
    "\n",
    "        \n",
    "        hidden_state = hidden_state.to(device)\n",
    "        action_probs = actor(hidden_state)[0] # remove batch dimension\n",
    "        value = critic(hidden_state)\n",
    "\n",
    "        action = torch.multinomial(action_probs, 1).item()\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        next_state_tensor = update_start_positions(layout_tensor, [next_state]).view(1, -1).to(device)\n",
    "\n",
    "        # Store rewards for later use\n",
    "        episode_rewards.append(reward)\n",
    "        with torch.no_grad():\n",
    "            # Encode the state\n",
    "            encoded_state = worldModel.encode(state_tensor, hidden_state)# could keep it from last output.\n",
    "\n",
    "        # Adjusting shapes\n",
    "        encoded_state_expanded = encoded_state.view(1, -1) \n",
    "        action_probs = action_probs.view(1, -1)\n",
    "        \n",
    "        # Concatenating tensors\n",
    "        # Note: All tensors now have a batch dimension of 1\n",
    "        # Integrated model loss\n",
    "        integratedModel_input = torch.cat((encoded_state_expanded, action_probs.detach()), dim=1)\n",
    "        # add batch because input needs to have batch, seq, input_size\n",
    "        integratedModel_input = integratedModel_input.view(1, 1, -1)\n",
    "        \n",
    "        # Now, use the flattened input for your integrated model\n",
    "        next_hidden_state, zt_hat, rt_hat, ct_hat, xt_hat, zt = worldModel(integratedModel_input, state_tensor, hidden_state)\n",
    "        xt = next_state_tensor.view(1, -1)\n",
    "        rt = torch.tensor(reward, device=device, dtype=torch.float).view(1, -1)\n",
    "        ct = torch.tensor(1 - int(done), device=device, dtype=torch.float).view(1, -1)\n",
    "        prediction_loss = (loss_fn(xt_hat, xt) \n",
    "                                + loss_fn(rt_hat, rt) \n",
    "                                + loss_fn(ct_hat, ct))\n",
    "        \n",
    "        zt = zt.view(1, 1, -1)\n",
    "        \n",
    "        threshold = 1\n",
    "        dynamic_loss = torch.max(torch.tensor(threshold), kl_loss(zt_hat, zt.detach()))\n",
    "        representation_loss = torch.max(torch.tensor(threshold), kl_loss(zt, zt_hat.detach()))\n",
    "        \n",
    "        worldModel_loss = Bpred * prediction_loss + Bdyn * dynamic_loss + Brep * representation_loss\n",
    "        \n",
    "        # Critic loss\n",
    "        target_value = reward + (gamma * critic(next_hidden_state.detach()) * (1 - int(done)))\n",
    "        critic_loss = F.mse_loss(value, target_value.detach())\n",
    "\n",
    "        # Actor loss\n",
    "        advantage = target_value - value\n",
    "        actor_loss = -torch.log(action_probs.squeeze(0)[action]) * advantage.detach()\n",
    "        \n",
    "    \n",
    "        # Backpropagation\n",
    "        critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(critic.parameters(), 100)\n",
    "        critic_optimizer.step()\n",
    "\n",
    "        actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(actor.parameters(), 100)\n",
    "        actor_optimizer.step()\n",
    "\n",
    "        \n",
    "        worldModel_optimizer.zero_grad()\n",
    "        worldModel_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(worldModel.parameters(), 1000)\n",
    "        worldModel_optimizer.step()\n",
    "    \n",
    "        # get gradients norms\n",
    "        critic_grads = sum([torch.norm(param.grad) for param in critic.parameters()])\n",
    "        actor_grads = sum([torch.norm(param.grad) for param in actor.parameters()])\n",
    "        worldModel_grads = sum([torch.norm(param.grad) for param in worldModel.parameters()])\n",
    "        \n",
    "        # get weights norms\n",
    "        critic_weights_norm = sum([torch.norm(param) for param in critic.parameters()])\n",
    "        actor_weights_norm = sum([torch.norm(param) for param in actor.parameters()])\n",
    "        worldModel_weights_norm = sum([torch.norm(param) for param in worldModel.parameters()])\n",
    "        \n",
    "        if logging:\n",
    "            wandb.log({\"critic_loss\": critic_loss.item(),\n",
    "                        \"critic_grads\": critic_grads,\n",
    "                        \"critic_weights_norm\": critic_weights_norm,\n",
    "                        \"actor_loss\": actor_loss.item(),\n",
    "                        \"actor_grads\": actor_grads,\n",
    "                        \"actor_weights_norm\": actor_weights_norm,\n",
    "                        \"integratedModel_loss\": worldModel_loss.item(),\n",
    "                        \"integratedModel_grads\": worldModel_grads,\n",
    "                        \"representation_loss\": representation_loss.item(),\n",
    "                        \"dynamic_loss\": dynamic_loss.item(),\n",
    "                        \"prediction_loss\": prediction_loss.item(),\n",
    "                        \"integratedModel_weights_norm\": worldModel_weights_norm,\n",
    "                       \"previous_episode_reward\": previous_episode_reward})\n",
    "        \n",
    "        state = next_state\n",
    "        hidden_state = next_hidden_state.detach()\n",
    "        max_steps -= 1\n",
    "    \n",
    "    previous_episode_reward = sum(episode_rewards)\n",
    "\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n",
    "\n",
    "if logging:\n",
    "    wandb.finish()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:45:11.373448Z",
     "start_time": "2024-01-15T21:38:36.182040Z"
    }
   },
   "id": "c61c1ee5397043e1",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.03\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "num_episodes = 100\n",
    "successes = 0\n",
    "for _ in range(num_episodes):\n",
    "    actor.eval()\n",
    "    critic.eval()\n",
    "    worldModel.eval()\n",
    "    \n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "    episode_rewards = []\n",
    "    layout_tensor = convert_layout_to_tensor([env.desc])\n",
    "    hidden_state = torch.zeros((1, 1, ht_size), device=device, dtype=torch.float)\n",
    "    \n",
    "    autoencoder_losses = []\n",
    "    \n",
    "    max_steps = 100\n",
    "    while not done and max_steps > 0:\n",
    "        state_tensor = update_start_positions(layout_tensor, [state])\n",
    "        state_tensor = state_tensor.view(1, -1).to(device)\n",
    "        with torch.no_grad():\n",
    "            # Encode the state\n",
    "            encoded_state = worldModel.encode(state_tensor, hidden_state)\n",
    "        encoded_state_expanded = encoded_state.view(1, -1)\n",
    "        \n",
    "        action_probs = actor(hidden_state)[0]\n",
    "        value = critic(hidden_state)\n",
    "\n",
    "        action = torch.multinomial(action_probs, 1).item()\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        next_state_tensor = update_start_positions(layout_tensor, [next_state])\n",
    "\n",
    "        # Store rewards for later use\n",
    "        episode_rewards.append(reward)\n",
    "        \n",
    "        integratedModel_input = torch.cat((encoded_state_expanded, action_probs.detach()), dim=1)\n",
    "        # add batch because input needs to have batch, seq, input_size\n",
    "        integratedModel_input = integratedModel_input.view(1, 1, -1)\n",
    "        hidden_state, _, _, _, _, _ = worldModel(integratedModel_input, state_tensor  ,hidden_state)\n",
    "        \n",
    "        state = next_state\n",
    "        max_steps -= 1\n",
    "\n",
    "    \n",
    "    if reward == 1:\n",
    "        successes += 1\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n",
    "print(f\"Success rate: {successes/num_episodes}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T21:47:16.324207Z",
     "start_time": "2024-01-15T21:47:09.824571Z"
    }
   },
   "id": "6e49f3d1bbeb16c9",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-15T21:45:11.437565Z"
    }
   },
   "id": "41413356ea1b0b78",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

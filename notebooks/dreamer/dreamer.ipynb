{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:36:13.797433Z",
     "start_time": "2024-01-14T20:36:13.771459Z"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import optuna\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map\n",
    "from gymnasium.vector import AsyncVectorEnv, SyncVectorEnv\n",
    "from collections import deque\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "FrozenLake environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f83b02f493c38fc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "env = gym.make('FrozenLake-v1', is_slippery=False)\n",
    "n_actions = env.action_space.n\n",
    "n_states = env.observation_space.n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:36:13.810136Z",
     "start_time": "2024-01-14T20:36:13.797525Z"
    }
   },
   "id": "f6f1fa210c2ad0e",
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def convert_layout_to_tensor(map_layouts):\n",
    "    nrows, ncols = len(map_layouts[0]), len(map_layouts[0][0])\n",
    "    num_statuses = 4\n",
    "    batch_size = len(map_layouts)\n",
    "\n",
    "    # Initialize a tensor for the batch of layouts\n",
    "    layout_tensor = torch.zeros((batch_size, nrows, ncols, num_statuses), device='cpu', dtype=torch.float)\n",
    "\n",
    "    layout_to_val = {b'F': 0, b'H': 1, b'S': 0, b'G': 3,\n",
    "                     'F': 0, 'H': 1, 'S': 0, 'G': 3}\n",
    "\n",
    "    # Precompute all indices for the batch\n",
    "    all_indices = [\n",
    "        layout_to_val[item]\n",
    "        for map_layout in map_layouts\n",
    "        for row in map_layout\n",
    "        for item in row\n",
    "    ]\n",
    "    indices_tensor = torch.tensor(all_indices, device='cpu').view(batch_size, nrows, ncols)\n",
    "\n",
    "    # Update the tensor using advanced indexing\n",
    "    layout_tensor.scatter_(3, indices_tensor.unsqueeze(3), 1)\n",
    "\n",
    "    return layout_tensor\n",
    "\n",
    "\n",
    "def update_start_positions(tensor_layout:Tensor, positions):\n",
    "    nrows, ncols, _ = tensor_layout.size()[1:4]\n",
    "\n",
    "    # Convert positions to a PyTorch tensor if it's not already one\n",
    "    if not isinstance(positions, torch.Tensor):\n",
    "        positions = torch.tensor(positions, dtype=torch.long, device=tensor_layout.device)\n",
    "\n",
    "    # Calculate rows and columns for all positions\n",
    "    rows = positions // ncols\n",
    "    cols = positions % ncols\n",
    "\n",
    "    # Reset the cells to [0, 0, 0, 0]\n",
    "    tensor_layout[torch.arange(positions.size(0)), rows, cols] = torch.tensor([0, 0, 0, 0], dtype=tensor_layout.dtype, device=tensor_layout.device)\n",
    "\n",
    "    # Set the start cells to [0, 0, 1, 0]\n",
    "    tensor_layout[torch.arange(positions.size(0)), rows, cols, 2] = 1\n",
    "\n",
    "    return tensor_layout"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:36:13.825094Z",
     "start_time": "2024-01-14T20:36:13.813658Z"
    }
   },
   "id": "44567364fcc9fa67",
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 1.]]]])\n",
      "tensor([[[[0., 0., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "tensor = convert_layout_to_tensor(generate_random_map(4))\n",
    "print(tensor)\n",
    "updated_tensor = update_start_positions(tensor, [[0]])\n",
    "print(updated_tensor) # dimensions: batch_size x nrows x ncols x num_statuses\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:36:13.826077Z",
     "start_time": "2024-01-14T20:36:13.817043Z"
    }
   },
   "id": "26914cb622923df9",
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implementation of DeamerV3 model\n",
    "![DeamerV3 model](model_names.png)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dd95da8c410c3ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Autoencoder that learns the latent space of the data\n",
    "class CategoricalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, latent_dim, num_categories):\n",
    "        super(CategoricalAutoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_categories = num_categories\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, latent_dim * num_categories)  # Output logits for each category in each latent dimension\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim * num_categories, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, input_size),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, temperature=1.0):\n",
    "        # Encode input and apply Gumbel Softmax\n",
    "        encoded = self.encoder(x)\n",
    "        encoded = encoded.view(-1, self.num_categories)\n",
    "        softmax = nn.functional.gumbel_softmax(encoded, tau=temperature, hard=True)\n",
    "        return softmax\n",
    "\n",
    "    def forward(self, x, temperature=1.0):\n",
    "        batch_size = x.size(0)\n",
    "        softmax = self.encode(x, temperature)\n",
    "        softmax = softmax.view(batch_size, -1)\n",
    "\n",
    "        x = self.decoder(softmax)\n",
    "        return x, softmax\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:36:13.826353Z",
     "start_time": "2024-01-14T20:36:13.821461Z"
    }
   },
   "id": "19b3561be99fe27f",
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sequence model that learns the dynamics of the latent space\n",
    "# takes as input h t-1, z t-1, a t-1 and outputs ht\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:36:13.828205Z",
     "start_time": "2024-01-14T20:36:13.825056Z"
    }
   },
   "id": "d35de25f9599dd11",
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Predictor model that predicts the next zt, rt, ct, xt\n",
    "class PredictorModel(nn.Module):\n",
    "    def __init__(self, gru_hidden_size, zt_dim, num_categories, reward_size, continue_size):\n",
    "        super(PredictorModel, self).__init__()\n",
    "        \n",
    "        # Shared Layers\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(gru_hidden_size, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Specific predictor for the latent space zt\n",
    "        self.dynamics_predictor = nn.Sequential(\n",
    "            nn.Linear(512, 256),  # Reduced dimensionality for specific prediction\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, zt_dim * num_categories)\n",
    "        )\n",
    "        \n",
    "        # Specific predictor for the reward rt\n",
    "        self.reward_predictor = nn.Sequential(\n",
    "            nn.Linear(512, 256),  # Same as above\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, reward_size)\n",
    "        )\n",
    "        \n",
    "        # Specific predictor for the continue signal ct\n",
    "        self.continue_predictor = nn.Sequential(\n",
    "            nn.Linear(512, 256),  # Same as above\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, continue_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, ht):\n",
    "        # Shared feature extraction\n",
    "        shared_features = self.shared_layers(ht)\n",
    "\n",
    "        # Predict the latent space zt using shared features\n",
    "        z_hat = self.dynamics_predictor(shared_features)\n",
    "        # Predict the reward rt using shared features\n",
    "        r_hat = self.reward_predictor(shared_features)\n",
    "        # Predict the continue signal ct using shared features\n",
    "        c_hat = self.continue_predictor(shared_features)\n",
    "\n",
    "        return z_hat, r_hat, c_hat\n",
    "\n",
    "class IntegratedModel(nn.Module):\n",
    "    def __init__(self, input_size, gru_hidden_size, num_layers, zt_dim, num_categories, reward_size, continue_size):\n",
    "        super(IntegratedModel, self).__init__()\n",
    "\n",
    "        self.gru_hidden_size = gru_hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size, gru_hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Shared Layers\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(gru_hidden_size, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Specific predictor for the latent space zt\n",
    "        self.dynamics_predictor = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, zt_dim * num_categories)\n",
    "        )\n",
    "        \n",
    "        # Specific predictor for the reward rt\n",
    "        self.reward_predictor = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, reward_size)\n",
    "        )\n",
    "        \n",
    "        # Specific predictor for the continue signal ct\n",
    "        self.continue_predictor = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, continue_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, h0=None):\n",
    "        if h0 is None:\n",
    "            # Initialize hidden state with zeros if not provided\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.gru_hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, hidden = self.gru(x, h0)\n",
    "\n",
    "        # Apply shared layers to the last hidden state\n",
    "        shared_features = self.shared_layers(out[:, -1, :])\n",
    "        \n",
    "        zt_hat = self.dynamics_predictor(shared_features)\n",
    "        rt_hat = self.reward_predictor(shared_features)\n",
    "        ct_hat = self.continue_predictor(shared_features)\n",
    "    \n",
    "        return hidden, zt_hat, rt_hat, ct_hat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:36:14.152101Z",
     "start_time": "2024-01-14T20:36:14.135720Z"
    }
   },
   "id": "cc7ed508cc0c5986",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the Actor Network\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 128)\n",
    "        self.fc2 = nn.Linear(128, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        action_probs = torch.softmax(self.fc2(x), dim=-1)\n",
    "        return action_probs\n",
    "\n",
    "# Define the Critic Network\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_size):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        value = self.fc2(x)\n",
    "        return value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:36:14.223685Z",
     "start_time": "2024-01-14T20:36:14.153915Z"
    }
   },
   "id": "7f334ff705d60e11",
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "640b615c97d3cb37"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = \"mps\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:36:14.229206Z",
     "start_time": "2024-01-14T20:36:14.166571Z"
    }
   },
   "id": "21168a3b14a069b2",
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "latent_size = 32 # aka zt size\n",
    "num_categories = 4 # number of categories in latent space\n",
    "autoencoder = CategoricalAutoencoder(4*4*4, latent_size, num_categories).to(device)\n",
    "autoencoder_optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "ht_size = 32\n",
    "reward_size = 1\n",
    "continue_size = 1\n",
    "integratedModel = IntegratedModel(latent_size * num_categories + n_actions, ht_size, 1, latent_size, num_categories, reward_size, continue_size).to(device)\n",
    "integratedModel_optimizer = optim.Adam(integratedModel.parameters(), lr=0.001)\n",
    "\n",
    "actor = Actor(ht_size, n_actions).to(device)\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=0.001)\n",
    "critic = Critic(ht_size).to(device)\n",
    "critic_optimizer = optim.Adam(critic.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:36:14.262534Z",
     "start_time": "2024-01-14T20:36:14.222713Z"
    }
   },
   "id": "6186b465c849ee41",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:24<00:00,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_episodes = 1000\n",
    "gamma = 0.99\n",
    "for episode in tqdm(range(num_episodes)):\n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "    episode_rewards = []\n",
    "    layout_tensor = convert_layout_to_tensor([env.desc]).to(device)\n",
    "    hidden_state = torch.zeros((1, 1, ht_size), device=device, dtype=torch.float)\n",
    "\n",
    "    while not done:\n",
    "        state_tensor = update_start_positions(layout_tensor, [state])\n",
    "        state_tensor = state_tensor.view(1, -1).to(device)\n",
    "\n",
    "        \n",
    "        hidden_state = hidden_state.to(device)\n",
    "        action_probs = actor(hidden_state)[0] # remove batch dimension\n",
    "        value = critic(hidden_state)\n",
    "\n",
    "        action = torch.multinomial(action_probs, 1).item()\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        next_state_tensor = update_start_positions(layout_tensor, [next_state]).view(1, -1).to(device)\n",
    "\n",
    "        # Store rewards for later use\n",
    "        episode_rewards.append(reward)\n",
    "        with torch.no_grad():\n",
    "            # Encode the state\n",
    "            encoded_state = autoencoder.encode(state_tensor)\n",
    "            encoded_next_state = autoencoder.encode(next_state_tensor)\n",
    "\n",
    "        # Adjusting shapes\n",
    "        encoded_state_expanded = encoded_state.view(1, -1) \n",
    "        action_probs = action_probs.view(1, -1)\n",
    "        \n",
    "        # Concatenating tensors\n",
    "        # Note: All tensors now have a batch dimension of 1\n",
    "        # Integrated model loss\n",
    "        integratedModel_input = torch.cat((encoded_state_expanded, action_probs.detach()), dim=1)\n",
    "        # add batch because input needs to have batch, seq, input_size\n",
    "        integratedModel_input = integratedModel_input.view(1, 1, -1)\n",
    "        \n",
    "        # Now, use the flattened input for your integrated model\n",
    "        next_hidden_state, zt_hat, rt_hat, ct_hat = integratedModel(integratedModel_input, hidden_state)\n",
    "        zt = encoded_next_state.view(1, -1)\n",
    "        rt = torch.tensor(reward, device=device, dtype=torch.float).view(1, -1)\n",
    "        ct = torch.tensor(1 - int(done), device=device, dtype=torch.float).view(1, -1)\n",
    "        integratedModel_loss = (F.mse_loss(zt_hat, zt) \n",
    "                                + F.mse_loss(rt_hat, rt) \n",
    "                                + F.mse_loss(ct_hat, ct))\n",
    "\n",
    "        # Critic loss\n",
    "        target_value = reward + (gamma * critic(next_hidden_state.detach()) * (1 - int(done)))\n",
    "        critic_loss = F.mse_loss(value, target_value.detach())\n",
    "\n",
    "        # Actor loss\n",
    "        advantage = target_value - value\n",
    "        actor_loss = -torch.log(action_probs.squeeze(0)[action]) * advantage.detach()\n",
    "\n",
    "        # Autoencoder loss\n",
    "        autoencoder_state, _ = autoencoder(state_tensor.detach())\n",
    "        autoencoder_loss = F.mse_loss(autoencoder_state, state_tensor)\n",
    "        \n",
    "    \n",
    "        # Backpropagation\n",
    "        critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        critic_optimizer.step()\n",
    "\n",
    "        actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        actor_optimizer.step()\n",
    "        \n",
    "        autoencoder_optimizer.zero_grad()\n",
    "        autoencoder_loss.backward()\n",
    "        autoencoder_optimizer.step()\n",
    "        \n",
    "        integratedModel_optimizer.zero_grad()\n",
    "        integratedModel_loss.backward()\n",
    "        integratedModel_optimizer.step()\n",
    "\n",
    "        state = next_state\n",
    "        hidden_state = next_hidden_state.detach()\n",
    "\n",
    "\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T13:37:41.147349Z",
     "start_time": "2024-01-15T13:32:16.777667Z"
    }
   },
   "id": "c61c1ee5397043e1",
   "execution_count": 130
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average autoencoder loss: 0.04757815150215345\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.028013118775561452\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.030369814950972795\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.038225468869010605\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.07207247552772363\n",
      "Exemple state: tensor([[0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.05040797744212406\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.03964992694091052\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.04065642710775137\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.0358418868007985\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.048251557939996324\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.044894636142998934\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.041698953757683434\n",
      "Exemple state: tensor([[0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.03872492164373398\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.038225468869010605\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.04777097861681666\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.04847359533111254\n",
      "Exemple state: tensor([[0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.028336715511977674\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.05256367567926645\n",
      "Exemple state: tensor([[0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.03586987633672026\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.03194094573458036\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.02826153626665473\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.029191466863267124\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.040293434634804726\n",
      "Exemple state: tensor([[0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.038225468869010605\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.038225468869010605\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.04197272378951311\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.040293434634804726\n",
      "Exemple state: tensor([[0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.027393165044486523\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.040976603205005326\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.040293434634804726\n",
      "Exemple state: tensor([[0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.04735948331654072\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.028556971739117917\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.03380977382001124\n",
      "Exemple state: tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n",
      "Average autoencoder loss: 0.03818515595048666\n",
      "Exemple state: tensor([[0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0')\n",
      "Exemple autoencoder state: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.1983, 0.0000, 0.8016, 0.0000, 0.4790,\n",
      "         0.0000, 0.0000, 0.0000, 0.6825, 0.0000, 0.3177, 0.0000, 0.0000, 0.0000,\n",
      "         0.2699, 0.0000, 0.0000, 0.9436, 0.0000, 0.0000, 0.9012, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9711, 0.0000, 0.0000, 0.9601, 0.0000, 0.0398, 0.0000,\n",
      "         0.9835, 0.0000, 0.0000, 0.0000, 0.9934, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.9930, 0.0000, 0.0000, 0.9989, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.0000]], device='mps:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[141], line 39\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# add batch because input needs to have batch, seq, input_size\u001B[39;00m\n\u001B[1;32m     38\u001B[0m integratedModel_input \u001B[38;5;241m=\u001B[39m integratedModel_input\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 39\u001B[0m hidden_state, _, _, _ \u001B[38;5;241m=\u001B[39m integratedModel(integratedModel_input, hidden_state)\n\u001B[1;32m     41\u001B[0m state \u001B[38;5;241m=\u001B[39m next_state\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# Test autoencoder loss\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/PytorchPractice/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/PytorchPractice/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[113], line 96\u001B[0m, in \u001B[0;36mIntegratedModel.forward\u001B[0;34m(self, x, h0)\u001B[0m\n\u001B[1;32m     94\u001B[0m zt_hat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdynamics_predictor(shared_features)\n\u001B[1;32m     95\u001B[0m rt_hat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreward_predictor(shared_features)\n\u001B[0;32m---> 96\u001B[0m ct_hat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontinue_predictor(shared_features)\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m hidden, zt_hat, rt_hat, ct_hat\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/PytorchPractice/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/PytorchPractice/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/PytorchPractice/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/PytorchPractice/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/PytorchPractice/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/PytorchPractice/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "num_episodes = 100\n",
    "successes = 0\n",
    "for _ in range(num_episodes):\n",
    "    actor.eval()\n",
    "    critic.eval()\n",
    "    autoencoder.eval()\n",
    "    integratedModel.eval()\n",
    "    \n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "    episode_rewards = []\n",
    "    layout_tensor = convert_layout_to_tensor([env.desc])\n",
    "    hidden_state = torch.zeros((1, 1, ht_size), device=device, dtype=torch.float)\n",
    "    \n",
    "    autoencoder_losses = []\n",
    "    \n",
    "    while not done:\n",
    "        state_tensor = update_start_positions(layout_tensor, [state])\n",
    "        state_tensor = state_tensor.view(1, -1).to(device)\n",
    "        with torch.no_grad():\n",
    "            # Encode the state\n",
    "            encoded_state = autoencoder.encode(state_tensor)\n",
    "        encoded_state_expanded = encoded_state.view(1, -1)\n",
    "        \n",
    "        action_probs = actor(hidden_state)[0]\n",
    "        value = critic(hidden_state)\n",
    "\n",
    "        action = torch.multinomial(action_probs, 1).item()\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        next_state_tensor = update_start_positions(layout_tensor, [next_state])\n",
    "\n",
    "        # Store rewards for later use\n",
    "        episode_rewards.append(reward)\n",
    "        \n",
    "        integratedModel_input = torch.cat((encoded_state_expanded, action_probs.detach()), dim=1)\n",
    "        # add batch because input needs to have batch, seq, input_size\n",
    "        integratedModel_input = integratedModel_input.view(1, 1, -1)\n",
    "        hidden_state, _, _, _ = integratedModel(integratedModel_input, hidden_state)\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        # Test autoencoder loss\n",
    "        autoencoder_state, _ = autoencoder(state_tensor.detach())\n",
    "        autoencoder_loss = F.mse_loss(autoencoder_state, state_tensor)\n",
    "        autoencoder_losses.append(autoencoder_loss.item())\n",
    "    \n",
    "    if reward == 1:\n",
    "        successes += 1\n",
    "    print(f\"Average autoencoder loss: {np.mean(autoencoder_losses)}\")\n",
    "    print(f\"Exemple state: {state_tensor}\")\n",
    "    print(f\"Exemple autoencoder state: {autoencoder_state}\")\n",
    "# Close the environment\n",
    "env.close()\n",
    "print(f\"Success rate: {successes/num_episodes}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T13:47:06.191123Z",
     "start_time": "2024-01-15T13:47:02.830760Z"
    }
   },
   "id": "6e49f3d1bbeb16c9",
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "41413356ea1b0b78"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
